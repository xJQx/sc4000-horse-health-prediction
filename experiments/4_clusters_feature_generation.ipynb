{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for testing using KMeans clusters as a new feature (Feature generation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "api = KaggleApi()\n",
    "api.authenticate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !kaggle competitions download -c playground-series-s3e22\n",
    "# !unzip -o playground-series-s3e22.zip\n",
    "# !kaggle datasets download yasserh/horse-survival-dataset\n",
    "# !unzip -o horse-survival-dataset.zip\n",
    "# !rm -rf playground-series-s3e22.zip horse-survival-dataset.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "_TRAIN_FILE = \"train.csv\"\n",
    "_TEST_FILE = \"test.csv\"\n",
    "_ORIGINAL_FILE = \"horse.csv\"\n",
    "_SAMPLE_SUBMISSION_FILE = \"sample_submission.csv\"\n",
    "\n",
    "_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clusterers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseClusterer:\n",
    "  X_columns = None\n",
    "  n_clusters = None\n",
    "  \n",
    "  def __init__(self):\n",
    "    pass\n",
    "\n",
    "  def fit(self, X_train):\n",
    "    raise NotImplementedError()\n",
    "\n",
    "  def get_cluster_numbers(self, X, train=True):\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" HDBSCAN (Hierarcical + Density/Non-Parametric)\n",
    "  https://hdbscan.readthedocs.io/en/latest/basic_hdbscan.html\n",
    "\"\"\"\n",
    "\n",
    "import hdbscan\n",
    "\n",
    "class HDBSCANClusterer(BaseClusterer):\n",
    "  def __init__(self, min_cluster_size=10):\n",
    "    self.hdbscan = None\n",
    "    self.X_columns = None\n",
    "\n",
    "    self.min_cluster_size = min_cluster_size\n",
    "\n",
    "  def fit(self, X_train):\n",
    "    # Initialize X_columns\n",
    "    self.X_columns = X_train.columns\n",
    "    \n",
    "    # Initialize the model\n",
    "    self.hdbscan = hdbscan.HDBSCAN(\n",
    "      cluster_selection_method='leaf', \n",
    "      min_cluster_size=self.min_cluster_size,\n",
    "      prediction_data=True\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    self.hdbscan.fit(X_train)\n",
    "\n",
    "    # Update number of clusters\n",
    "    self.n_clusters = self.hdbscan.labels_.max() + 1\n",
    "\n",
    "  def get_cluster_numbers(self, X, train=True):\n",
    "    if not self.hdbscan:\n",
    "      raise Exception(\"HDBSCANClusterer not initialised!\")\n",
    "    \n",
    "    cluster_numbers = self.hdbscan.labels_ if train else hdbscan.approximate_predict(self.hdbscan, X)[0]\n",
    "    return cluster_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" KMeans (Flat + Centroid/Parametric)\n",
    "  https://scikit-learn.org/1.5/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "class KMeansClusterer(BaseClusterer):\n",
    "  def __init__(self, n_clusters=8):\n",
    "    self.kmeans = None\n",
    "    self.X_columns = None\n",
    "    self.n_clusters = n_clusters\n",
    "\n",
    "  def fit(self, X_train):\n",
    "    # Initialize X_columns\n",
    "    self.X_columns = X_train.columns\n",
    "    \n",
    "    # Initialize the model\n",
    "    self.kmeans = KMeans(n_clusters=self.n_clusters, random_state=_SEED)\n",
    "\n",
    "    # Train the model\n",
    "    self.kmeans.fit(X_train)\n",
    "\n",
    "  def get_cluster_numbers(self, X, train=True):\n",
    "    if not self.kmeans:\n",
    "      raise Exception(\"KMeansClusterer not initialised!\")\n",
    "    \n",
    "    cluster_numbers = self.kmeans.labels_ if train else self.kmeans.predict(X)\n",
    "    return cluster_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Mean Shift (Flat + Density/Non-Parametric)\n",
    "  https://scikit-learn.org/1.5/modules/generated/sklearn.cluster.MeanShift.html#sklearn.cluster.MeanShift\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.cluster import MeanShift\n",
    "\n",
    "class MeanShiftClusterer(BaseClusterer):\n",
    "  def __init__(self, cluster_all=True):\n",
    "    self.mean_shift = None\n",
    "    self.X_columns = None\n",
    "    self.cluster_all = cluster_all\n",
    "\n",
    "  def fit(self, X_train):\n",
    "    # Initialize X_columns\n",
    "    self.X_columns = X_train.columns\n",
    "    \n",
    "    # Initialize the model\n",
    "    self.mean_shift = MeanShift(\n",
    "      cluster_all=self.cluster_all\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    self.mean_shift.fit(X_train)\n",
    "\n",
    "    # Update number of clusters\n",
    "    self.n_clusters = self.mean_shift.labels_.max() + 1\n",
    "\n",
    "  def get_cluster_numbers(self, X, train=True):\n",
    "    if not self.mean_shift:\n",
    "      raise Exception(\"MeanShiftClusterer not initialised!\")\n",
    "    \n",
    "    cluster_numbers = self.mean_shift.labels_ if train else self.mean_shift.predict(X)\n",
    "    return cluster_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" AgglomerativeClustering (Hierarcical + Centroid/Parametric)\n",
    "  https://scikit-learn.org/1.5/modules/generated/sklearn.cluster.AgglomerativeClustering.html#sklearn.cluster.AgglomerativeClustering\n",
    "\n",
    "  linkage='ward' minimizes the variance of the clusters being merged.\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "class AgglomerativeClusterer(BaseClusterer):\n",
    "  def __init__(self, n_clusters=8):\n",
    "    self.agglomerative = None\n",
    "    self.X_columns = None\n",
    "    self.n_clusters = n_clusters\n",
    "\n",
    "  def fit(self, X_train):\n",
    "    # Initialize X_columns\n",
    "    self.X_columns = X_train.columns\n",
    "    \n",
    "    # Initialize the model\n",
    "    self.agglomerative = AgglomerativeClustering(\n",
    "      n_clusters=self.n_clusters,\n",
    "      linkage=\"ward\"\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    self.agglomerative.fit(X_train)\n",
    "\n",
    "  def get_cluster_numbers(self, X, train=True):\n",
    "    if not self.agglomerative:\n",
    "      raise Exception(\"AgglomerativeClusterer not initialised!\")\n",
    "    \n",
    "    cluster_numbers = self.agglomerative.labels_ if train else self.agglomerative.fit_predict(X)\n",
    "    return cluster_numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "def preprocess_data(df, clusterer:BaseClusterer=None, train=True):\n",
    "    # Separate features and target\n",
    "    if train:\n",
    "        cols_to_drop = [\"outcome\", \"id\"]\n",
    "    else:\n",
    "        cols_to_drop = [\"id\"]\n",
    "\n",
    "    # Simple handling of NA values: drop rows with missing values\n",
    "    if train:\n",
    "        df = df.dropna()\n",
    "\n",
    "    X = df.drop(columns=cols_to_drop)\n",
    "\n",
    "    if \"outcome\" in df.columns:\n",
    "        y = df[\"outcome\"]\n",
    "    else:\n",
    "        y = None\n",
    "    \n",
    "    # One hot encoding\n",
    "    X = pd.get_dummies(X)\n",
    "\n",
    "    if not train:\n",
    "        # Reindex test columns to include all categorical features encoded during training\n",
    "        X = X.reindex(columns=clusterer.X_columns, fill_value=0)\n",
    "\n",
    "    # Only Use Important Features\n",
    "    selected_features = [\n",
    "        'rectal_temp', 'pulse', 'respiratory_rate', 'nasogastric_reflux_ph',\n",
    "        'packed_cell_volume', 'total_protein', 'abdomo_protein', 'lesion_1',\n",
    "        'surgery_no', 'surgery_yes', 'temp_of_extremities_cool',\n",
    "        'peripheral_pulse_reduced', 'capillary_refill_time_more_3_sec',\n",
    "        'pain_depressed', 'pain_mild_pain', 'pain_severe_pain', 'peristalsis_absent',\n",
    "        'abdominal_distention_moderate', 'nasogastric_reflux_more_1_liter',\n",
    "        'rectal_exam_feces_absent', 'abdomen_distend_large',\n",
    "        'abdomo_appearance_serosanguious', 'surgical_lesion_no',\n",
    "        'surgical_lesion_yes', 'cp_data_no', 'mucous_membrane_normal_pink',\n",
    "        'abdomo_appearance_cloudy', 'capillary_refill_time_less_3_sec',\n",
    "        'peripheral_pulse_normal', 'nasogastric_tube_slight',\n",
    "        'mucous_membrane_pale_pink', 'pain_extreme_pain',\n",
    "        'mucous_membrane_pale_cyanotic', 'abdomen_distend_small', 'cp_data_yes',\n",
    "        'abdominal_distention_slight', 'temp_of_extremities_normal',\n",
    "        'mucous_membrane_bright_red', 'abdominal_distention_severe',\n",
    "        'abdomo_appearance_clear', 'rectal_exam_feces_decreased',\n",
    "        'peristalsis_hypomotile', 'age_young', 'nasogastric_reflux_less_1_liter',\n",
    "        'rectal_exam_feces_normal', 'temp_of_extremities_cold', 'abdomen_firm',\n",
    "        'pain_alert', 'nasogastric_tube_significant',\n",
    "        'mucous_membrane_dark_cyanotic', 'peristalsis_normal', 'abdomen_normal',\n",
    "        'mucous_membrane_bright_pink', 'age_adult', 'peripheral_pulse_absent',\n",
    "        'rectal_exam_feces_increased'\n",
    "    ]\n",
    "    X = X[selected_features]\n",
    "\n",
    "    # SMOTE Oversampling of minority classes (During training stage)\n",
    "    if train:\n",
    "        smote = SMOTE(random_state=_SEED)\n",
    "        X, y = smote.fit_resample(X, y)\n",
    "\n",
    "    # Generate Cluster Numbers\n",
    "    if clusterer:\n",
    "        if train:\n",
    "            clusterer.fit(X)\n",
    "        cluster_numbers = clusterer.get_cluster_numbers(X, train=train)\n",
    "        X[\"cluster_number\"] = cluster_numbers\n",
    "\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "train_df = pd.read_csv(_TRAIN_FILE)\n",
    "test_df = pd.read_csv(_TEST_FILE)\n",
    "original_df = pd.read_csv(_ORIGINAL_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "\n",
    "def run(df: pd.DataFrame, experiment_name: str, clusterer:BaseClusterer=None):\n",
    "    print(f\"========== {experiment_name} ==========\")\n",
    "\n",
    "    X, y = preprocess_data(df, clusterer)\n",
    "\n",
    "    forest = RandomForestClassifier(random_state=_SEED)\n",
    "\n",
    "    k_folds = KFold(n_splits=20)\n",
    "\n",
    "    scores = cross_val_score(forest, X, y, cv=k_folds, scoring=\"f1_micro\")\n",
    "    f1_score_micro_avg = scores.mean()\n",
    "\n",
    "    print(\"F1 Score (Micro-Averaged):\", f1_score_micro_avg)\n",
    "\n",
    "    return f1_score_micro_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To store experiment results\n",
    "result_f1_scores = []\n",
    "result_clusterers = []\n",
    "result_n_clusters = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Without KMeans Clusters (0 clusters) ==========\n",
      "F1 Score (Micro-Averaged): 0.8090895341802783\n"
     ]
    }
   ],
   "source": [
    "#############################################\n",
    "############### No Clustering ###############\n",
    "#############################################\n",
    "\n",
    "base_f1_score_micro_avg = run(pd.concat((train_df, original_df), axis=0), \"Without KMeans Clusters (0 clusters)\")\n",
    "\n",
    "# Save results to array\n",
    "result_f1_scores.append(base_f1_score_micro_avg)\n",
    "result_clusterers.append(\"-\")\n",
    "result_n_clusters.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== With HDBSCAN Clusters ==========\n",
      "F1 Score (Micro-Averaged): 0.8177858439201451\n"
     ]
    }
   ],
   "source": [
    "#################################################\n",
    "############### HDBSCAN Custering ###############\n",
    "#################################################\n",
    "\n",
    "# HDB_PARAMS_SEARCH_SPACE = {\n",
    "#   \"min_cluster_size\": [5, 10, 15, 20],\n",
    "#   \"min_samples\": [3, 5, 7, 15, 24, 30],\n",
    "#   \"cluster_selection_epsilon\": [0] # No difference\n",
    "# }\n",
    "# Best Test Score is min_cluster_size=10 and rest default\n",
    "\n",
    "hdbscan_clusterer = HDBSCANClusterer(\n",
    "  min_cluster_size=10\n",
    ")\n",
    "\n",
    "f1_score_micro_avg = run(\n",
    "  pd.concat((train_df, original_df), axis=0), \n",
    "  f\"With HDBSCAN Clusters\", \n",
    "  clusterer=hdbscan_clusterer\n",
    ")\n",
    "\n",
    "# Save results to array\n",
    "result_f1_scores.append(f1_score_micro_avg)\n",
    "result_clusterers.append(\"HDBSCAN\")\n",
    "result_n_clusters.append(hdbscan_clusterer.n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== With KMeans Clusters (3 clusters) ==========\n",
      "F1 Score (Micro-Averaged): 0.8142468239564428\n",
      "========== With KMeans Clusters (6 clusters) ==========\n",
      "F1 Score (Micro-Averaged): 0.8073805202661827\n",
      "========== With KMeans Clusters (8 clusters) ==========\n",
      "F1 Score (Micro-Averaged): 0.813475499092559\n",
      "========== With KMeans Clusters (12 clusters) ==========\n",
      "F1 Score (Micro-Averaged): 0.8091349062310951\n",
      "========== With KMeans Clusters (16 clusters) ==========\n",
      "F1 Score (Micro-Averaged): 0.8091802782819117\n",
      "========== With KMeans Clusters (24 clusters) ==========\n",
      "F1 Score (Micro-Averaged): 0.8081820931639443\n"
     ]
    }
   ],
   "source": [
    "#################################################\n",
    "############### KMeans Clustering ###############\n",
    "#################################################\n",
    "\n",
    "N_CLUSTERS = [\n",
    "  3, 6, 8, 12, 16, 24\n",
    "]\n",
    "\n",
    "for n_clusters in N_CLUSTERS:\n",
    "  f1_score_micro_avg = run(\n",
    "    pd.concat((train_df, original_df), axis=0), \n",
    "    f\"With KMeans Clusters ({n_clusters} clusters)\", \n",
    "    clusterer=KMeansClusterer(n_clusters=n_clusters)\n",
    "  )\n",
    "\n",
    "  # Save results to array\n",
    "  result_f1_scores.append(f1_score_micro_avg)\n",
    "  result_clusterers.append(\"KMeans\")\n",
    "  result_n_clusters.append(n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== With MeanShift Clusters (Cluster All Points) ==========\n",
      "F1 Score (Micro-Averaged): 0.8169540229885056\n",
      "========== With MeanShift Clusters (Exclude Orphans Points) ==========\n",
      "F1 Score (Micro-Averaged): 0.8168330308529945\n"
     ]
    }
   ],
   "source": [
    "#################################################\n",
    "############## MeanShift Custering ##############\n",
    "#################################################\n",
    "\n",
    "cluster_all_params = [True, False]\n",
    "\n",
    "for cluster_all in cluster_all_params:\n",
    "  mean_shift_clusterer = MeanShiftClusterer(cluster_all=cluster_all)\n",
    "\n",
    "  f1_score_micro_avg = run(\n",
    "    pd.concat((train_df, original_df), axis=0), \n",
    "    f\"With MeanShift Clusters ({'Cluster All Points' if cluster_all else 'Exclude Orphans Points'})\", \n",
    "    clusterer=mean_shift_clusterer\n",
    "  )\n",
    "\n",
    "  # Save results to array\n",
    "  result_f1_scores.append(f1_score_micro_avg)\n",
    "  result_clusterers.append(f\"MeanShift ({'Cluster All Points' if cluster_all else 'Exclude Orphans Points'})\")\n",
    "  result_n_clusters.append(mean_shift_clusterer.n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== With Agglomerative Clusters (3 clusters) ==========\n",
      "F1 Score (Micro-Averaged): 0.8160768300060497\n",
      "========== With Agglomerative Clusters (6 clusters) ==========\n",
      "F1 Score (Micro-Averaged): 0.8117513611615245\n",
      "========== With Agglomerative Clusters (12 clusters) ==========\n",
      "F1 Score (Micro-Averaged): 0.8055958862673928\n",
      "========== With Agglomerative Clusters (16 clusters) ==========\n",
      "F1 Score (Micro-Averaged): 0.8177858439201451\n",
      "========== With Agglomerative Clusters (24 clusters) ==========\n",
      "F1 Score (Micro-Averaged): 0.8133545069570477\n"
     ]
    }
   ],
   "source": [
    "#################################################\n",
    "########### Agglomerative Clustering ############\n",
    "#################################################\n",
    "\n",
    "N_CLUSTERS = [\n",
    "  3, 6, 12, 16, 24\n",
    "]\n",
    "\n",
    "for n_clusters in N_CLUSTERS:\n",
    "  f1_score_micro_avg = run(\n",
    "    pd.concat((train_df, original_df), axis=0), \n",
    "    f\"With Agglomerative Clusters ({n_clusters} clusters)\", \n",
    "    clusterer=AgglomerativeClusterer(n_clusters=n_clusters)\n",
    "  )\n",
    "\n",
    "  # Save results to array\n",
    "  result_f1_scores.append(f1_score_micro_avg)\n",
    "  result_clusterers.append(\"Agglomerative\")\n",
    "  result_n_clusters.append(n_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clusterer</th>\n",
       "      <th>n_clusters</th>\n",
       "      <th>f1_score_micro_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HDBSCAN</td>\n",
       "      <td>21</td>\n",
       "      <td>0.817786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Agglomerative</td>\n",
       "      <td>16</td>\n",
       "      <td>0.817786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MeanShift (Cluster All Points)</td>\n",
       "      <td>7</td>\n",
       "      <td>0.816954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MeanShift (Exclude Orphans Points)</td>\n",
       "      <td>7</td>\n",
       "      <td>0.816833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Agglomerative</td>\n",
       "      <td>3</td>\n",
       "      <td>0.816077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KMeans</td>\n",
       "      <td>3</td>\n",
       "      <td>0.814247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KMeans</td>\n",
       "      <td>8</td>\n",
       "      <td>0.813475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Agglomerative</td>\n",
       "      <td>24</td>\n",
       "      <td>0.813355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Agglomerative</td>\n",
       "      <td>6</td>\n",
       "      <td>0.811751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KMeans</td>\n",
       "      <td>16</td>\n",
       "      <td>0.809180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>KMeans</td>\n",
       "      <td>12</td>\n",
       "      <td>0.809135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>0.809090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KMeans</td>\n",
       "      <td>24</td>\n",
       "      <td>0.808182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KMeans</td>\n",
       "      <td>6</td>\n",
       "      <td>0.807381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Agglomerative</td>\n",
       "      <td>12</td>\n",
       "      <td>0.805596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             clusterer  n_clusters  f1_score_micro_avg\n",
       "0                              HDBSCAN          21            0.817786\n",
       "1                        Agglomerative          16            0.817786\n",
       "2       MeanShift (Cluster All Points)           7            0.816954\n",
       "3   MeanShift (Exclude Orphans Points)           7            0.816833\n",
       "4                        Agglomerative           3            0.816077\n",
       "5                               KMeans           3            0.814247\n",
       "6                               KMeans           8            0.813475\n",
       "7                        Agglomerative          24            0.813355\n",
       "8                        Agglomerative           6            0.811751\n",
       "9                               KMeans          16            0.809180\n",
       "10                              KMeans          12            0.809135\n",
       "11                                   -           0            0.809090\n",
       "12                              KMeans          24            0.808182\n",
       "13                              KMeans           6            0.807381\n",
       "14                       Agglomerative          12            0.805596"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\n",
    "  \"clusterer\": result_clusterers,\n",
    "  \"n_clusters\": result_n_clusters,\n",
    "  \"f1_score_micro_avg\": result_f1_scores\n",
    "}).sort_values(by=\"f1_score_micro_avg\", ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterer = HDBSCANClusterer(min_cluster_size=10)\n",
    "\n",
    "X, y = preprocess_data(pd.concat((train_df, original_df), axis=0), clusterer=clusterer)\n",
    "forest = RandomForestClassifier(random_state=_SEED)\n",
    "forest.fit(X, y)\n",
    "\n",
    "X_submit, _ = preprocess_data(test_df, clusterer=clusterer, train=False)\n",
    "X_submit = X_submit.reindex(columns=X.columns, fill_value=0)\n",
    "\n",
    "y_pred_submit = forest.predict(X_submit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df = pd.DataFrame({\"id\": test_df[\"id\"], \"outcome\": y_pred_submit})\n",
    "save_df.to_csv(\"submission.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully submitted to Predict Health Outcomes of Horses\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/9.92k [00:00<?, ?B/s]\n",
      "100%|██████████| 9.92k/9.92k [00:01<00:00, 9.71kB/s]\n"
     ]
    }
   ],
   "source": [
    "# !kaggle competitions submit -c playground-series-s3e22 -f submission.csv -m \"SMOTE + Top Features + HDBSCAN cluster\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
